"""
AutoTriage & AutoFix Agent - S3 Tool

This module provides Amazon S3 integration for storing artifacts, logs,
and other data generated by the autonomous agent workflow.
"""

import os
import json
import logging
import boto3
from typing import Dict, Any, Optional, Union
from datetime import datetime, timezone
from botocore.exceptions import ClientError

# Configure logging
logger = logging.getLogger(__name__)

class S3Tool:
    """Amazon S3 integration tool for artifact and log storage."""
    
    def __init__(self):
        """Initialize S3 tool with AWS credentials."""
        self.client = boto3.client('s3')
        self.bucket_name = os.environ.get('S3_BUCKET')
        
        if not self.bucket_name:
            logger.warning("S3_BUCKET not configured")
    
    def store_artifact(self, bucket: str, key: str, data: Union[dict, str, bytes], 
                      content_type: str = 'application/json') -> Dict[str, Any]:
        """
        Store an artifact in S3.
        
        Args:
            bucket: S3 bucket name
            key: S3 object key
            data: Data to store (dict, str, or bytes)
            content_type: MIME type of the content
            
        Returns:
            Storage result
        """
        try:
            # Convert data to bytes if needed
            if isinstance(data, dict):
                body = json.dumps(data, indent=2, default=str).encode('utf-8')
                content_type = 'application/json'
            elif isinstance(data, str):
                body = data.encode('utf-8')
            else:
                body = data
            
            # Upload to S3
            self.client.put_object(
                Bucket=bucket,
                Key=key,
                Body=body,
                ContentType=content_type,
                Metadata={
                    'created_by': 'autofix-agent',
                    'timestamp': datetime.now(timezone.utc).isoformat()
                }
            )
            
            logger.info(f"Stored artifact: s3://{bucket}/{key}")
            
            return {
                'success': True,
                'bucket': bucket,
                'key': key,
                'size': len(body),
                'content_type': content_type
            }
            
        except ClientError as e:
            logger.error(f"S3 storage error: {e}")
            return {
                'success': False,
                'error': f'S3 storage failed: {str(e)}'
            }
        except Exception as e:
            logger.error(f"Error storing artifact: {e}")
            return {
                'success': False,
                'error': f'Storage failed: {str(e)}'
            }
    
    def retrieve_artifact(self, bucket: str, key: str) -> Dict[str, Any]:
        """
        Retrieve an artifact from S3.
        
        Args:
            bucket: S3 bucket name
            key: S3 object key
            
        Returns:
            Retrieved artifact data
        """
        try:
            response = self.client.get_object(Bucket=bucket, Key=key)
            
            # Read the object content
            body = response['Body'].read()
            content_type = response.get('ContentType', 'application/octet-stream')
            
            # Parse JSON if content type indicates it
            if content_type == 'application/json':
                try:
                    data = json.loads(body.decode('utf-8'))
                except json.JSONDecodeError:
                    data = body.decode('utf-8')
            else:
                data = body
            
            return {
                'success': True,
                'data': data,
                'content_type': content_type,
                'size': len(body),
                'last_modified': response.get('LastModified'),
                'metadata': response.get('Metadata', {})
            }
            
        except ClientError as e:
            error_code = e.response['Error']['Code']
            if error_code == 'NoSuchKey':
                return {
                    'success': False,
                    'error': f'Artifact not found: s3://{bucket}/{key}'
                }
            else:
                logger.error(f"S3 retrieval error: {e}")
                return {
                    'success': False,
                    'error': f'S3 retrieval failed: {str(e)}'
                }
        except Exception as e:
            logger.error(f"Error retrieving artifact: {e}")
            return {
                'success': False,
                'error': f'Retrieval failed: {str(e)}'
            }
    
    def store_agent_logs(self, issue_id: str, logs: list, 
                        bucket: str = None) -> Dict[str, Any]:
        """
        Store agent execution logs for an issue.
        
        Args:
            issue_id: GitHub issue ID
            logs: List of log entries
            bucket: S3 bucket name (uses default if not provided)
            
        Returns:
            Storage result
        """
        bucket = bucket or self.bucket_name
        if not bucket:
            return {
                'success': False,
                'error': 'S3 bucket not configured'
            }
        
        timestamp = datetime.now(timezone.utc)
        key = f"logs/{issue_id}/{timestamp.strftime('%Y%m%d_%H%M%S')}.json"
        
        log_data = {
            'issue_id': issue_id,
            'timestamp': timestamp.isoformat(),
            'logs': logs,
            'count': len(logs)
        }
        
        return self.store_artifact(bucket, key, log_data)
    
    def store_patch_artifact(self, issue_id: str, patch_content: str, 
                            metadata: dict = None, bucket: str = None) -> Dict[str, Any]:
        """
        Store a code patch artifact.
        
        Args:
            issue_id: GitHub issue ID
            patch_content: Unified diff patch content
            metadata: Additional metadata
            bucket: S3 bucket name (uses default if not provided)
            
        Returns:
            Storage result
        """
        bucket = bucket or self.bucket_name
        if not bucket:
            return {
                'success': False,
                'error': 'S3 bucket not configured'
            }
        
        timestamp = datetime.now(timezone.utc)
        key = f"patches/{issue_id}/{timestamp.strftime('%Y%m%d_%H%M%S')}.patch"
        
        # Prepare metadata
        artifact_metadata = {
            'issue_id': issue_id,
            'timestamp': timestamp.isoformat(),
            'type': 'patch',
            'size': len(patch_content)
        }
        
        if metadata:
            artifact_metadata.update(metadata)
        
        return self.store_artifact(bucket, key, patch_content, 'text/plain')
    
    def store_test_results(self, build_id: str, test_results: dict, 
                          bucket: str = None) -> Dict[str, Any]:
        """
        Store CodeBuild test results.
        
        Args:
            build_id: CodeBuild build ID
            test_results: Test results data
            bucket: S3 bucket name (uses default if not provided)
            
        Returns:
            Storage result
        """
        bucket = bucket or self.bucket_name
        if not bucket:
            return {
                'success': False,
                'error': 'S3 bucket not configured'
            }
        
        timestamp = datetime.now(timezone.utc)
        key = f"test-results/{build_id}/{timestamp.strftime('%Y%m%d_%H%M%S')}.json"
        
        return self.store_artifact(bucket, key, test_results)
    
    def store_agent_memory(self, issue_id: str, memory_data: dict, 
                          bucket: str = None) -> Dict[str, Any]:
        """
        Store agent memory/learning data.
        
        Args:
            issue_id: GitHub issue ID
            memory_data: Memory/learning data
            bucket: S3 bucket name (uses default if not provided)
            
        Returns:
            Storage result
        """
        bucket = bucket or self.bucket_name
        if not bucket:
            return {
                'success': False,
                'error': 'S3 bucket not configured'
            }
        
        timestamp = datetime.now(timezone.utc)
        key = f"memory/{issue_id}/{timestamp.strftime('%Y%m%d_%H%M%S')}.json"
        
        memory_artifact = {
            'issue_id': issue_id,
            'timestamp': timestamp.isoformat(),
            'memory_data': memory_data,
            'type': 'agent_memory'
        }
        
        return self.store_artifact(bucket, key, memory_artifact)
    
    def list_artifacts(self, prefix: str, bucket: str = None, 
                      max_keys: int = 100) -> Dict[str, Any]:
        """
        List artifacts with a given prefix.
        
        Args:
            prefix: S3 key prefix
            bucket: S3 bucket name (uses default if not provided)
            max_keys: Maximum number of keys to return
            
        Returns:
            List of artifacts
        """
        bucket = bucket or self.bucket_name
        if not bucket:
            return {
                'success': False,
                'error': 'S3 bucket not configured'
            }
        
        try:
            response = self.client.list_objects_v2(
                Bucket=bucket,
                Prefix=prefix,
                MaxKeys=max_keys
            )
            
            artifacts = []
            for obj in response.get('Contents', []):
                artifacts.append({
                    'key': obj['Key'],
                    'size': obj['Size'],
                    'last_modified': obj['LastModified'],
                    'etag': obj['ETag']
                })
            
            return {
                'success': True,
                'artifacts': artifacts,
                'count': len(artifacts),
                'is_truncated': response.get('IsTruncated', False)
            }
            
        except ClientError as e:
            logger.error(f"S3 listing error: {e}")
            return {
                'success': False,
                'error': f'S3 listing failed: {str(e)}'
            }
        except Exception as e:
            logger.error(f"Error listing artifacts: {e}")
            return {
                'success': False,
                'error': f'Listing failed: {str(e)}'
            }
    
    def delete_artifact(self, bucket: str, key: str) -> Dict[str, Any]:
        """
        Delete an artifact from S3.
        
        Args:
            bucket: S3 bucket name
            key: S3 object key
            
        Returns:
            Deletion result
        """
        try:
            self.client.delete_object(Bucket=bucket, Key=key)
            
            logger.info(f"Deleted artifact: s3://{bucket}/{key}")
            
            return {
                'success': True,
                'bucket': bucket,
                'key': key
            }
            
        except ClientError as e:
            logger.error(f"S3 deletion error: {e}")
            return {
                'success': False,
                'error': f'S3 deletion failed: {str(e)}'
            }
        except Exception as e:
            logger.error(f"Error deleting artifact: {e}")
            return {
                'success': False,
                'error': f'Deletion failed: {str(e)}'
            }
    
    def generate_presigned_url(self, bucket: str, key: str, 
                             expiration: int = 3600) -> Dict[str, Any]:
        """
        Generate a presigned URL for an S3 object.
        
        Args:
            bucket: S3 bucket name
            key: S3 object key
            expiration: URL expiration time in seconds
            
        Returns:
            Presigned URL result
        """
        try:
            url = self.client.generate_presigned_url(
                'get_object',
                Params={'Bucket': bucket, 'Key': key},
                ExpiresIn=expiration
            )
            
            return {
                'success': True,
                'url': url,
                'expires_in': expiration
            }
            
        except ClientError as e:
            logger.error(f"S3 presigned URL error: {e}")
            return {
                'success': False,
                'error': f'Presigned URL generation failed: {str(e)}'
            }
        except Exception as e:
            logger.error(f"Error generating presigned URL: {e}")
            return {
                'success': False,
                'error': f'URL generation failed: {str(e)}'
            }
    
    def get_artifact_metadata(self, bucket: str, key: str) -> Dict[str, Any]:
        """
        Get metadata for an S3 object.
        
        Args:
            bucket: S3 bucket name
            key: S3 object key
            
        Returns:
            Object metadata
        """
        try:
            response = self.client.head_object(Bucket=bucket, Key=key)
            
            return {
                'success': True,
                'content_type': response.get('ContentType'),
                'content_length': response.get('ContentLength'),
                'last_modified': response.get('LastModified'),
                'etag': response.get('ETag'),
                'metadata': response.get('Metadata', {}),
                'storage_class': response.get('StorageClass')
            }
            
        except ClientError as e:
            error_code = e.response['Error']['Code']
            if error_code == 'NoSuchKey':
                return {
                    'success': False,
                    'error': f'Object not found: s3://{bucket}/{key}'
                }
            else:
                logger.error(f"S3 metadata error: {e}")
                return {
                    'success': False,
                    'error': f'S3 metadata retrieval failed: {str(e)}'
                }
        except Exception as e:
            logger.error(f"Error getting artifact metadata: {e}")
            return {
                'success': False,
                'error': f'Metadata retrieval failed: {str(e)}'
            }
